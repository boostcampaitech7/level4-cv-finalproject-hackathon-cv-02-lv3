from bayes_opt import BayesianOptimization
from bayes_opt.util import UtilityFunction
import numpy as np
import joblib
import pandas as pd
import argparse  # ì‹¤í–‰ ëª¨ë“œ ì„ íƒì„ ìœ„í•´ ì¶”ê°€
import time  # ì‹¤í–‰ ì‹œê°„ ì¸¡ì •ì„ ìœ„í•œ ëª¨ë“ˆ
from joblib import Parallel, delayed
from shapely.geometry import Point, Polygon
import alphashape
import random
from sklearn.preprocessing import MinMaxScaler



# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv('melb_split.csv')
drop_tables = ['Suburb', 'Address', 'Rooms', 'Method', 'SellerG', 'Date', 'Distance', 'Postcode',
               'Bedroom2', 'Bathroom', 'Car', 'Landsize', 'YearBuilt', 'CouncilArea',
               'Regionname', 'Propertycount', 'Split']
df = df.drop(drop_tables, axis=1)
df = df.dropna(axis=0)

index = 0.1 < df['BuildingArea']  # BuildingArea 0ê°’ ì œê±°
df = df.loc[index]

# ë² ì´ì§€ì•ˆ ìµœì í™”ì—ëŠ” train/test ë‚˜ëˆŒ í•„ìš” ì—†ìŒ
train_data = pd.get_dummies(df, dtype='float')

# íƒ€ê²Ÿ ë³€ìˆ˜ì™€ íŠ¹ì„± ë¶„ë¦¬
y_train = train_data['Price']
X_train = train_data.drop(['Price'], axis=1)



# ë°ì´í„° ì •ì˜
search_y = {
    "price": {
        "ëª©í‘œ": "ìµœëŒ€í™”í•˜ê¸°",
        "ìˆœìœ„": 1
    }
}

search_x = {
    "lattitude": {
        "ëª©í‘œ": "ìµœì†Œí™”í•˜ê¸°",
        "ë²”ìœ„ ì„¤ì •": [0, 1],
        "ìˆœìœ„": 4
    },
    "longitude": {
        "ëª©í‘œ": "ìµœì†Œí™”í•˜ê¸°",
        "ë²”ìœ„ ì„¤ì •": [0, 1],
        "ìˆœìœ„": 3
    }
}



def calculate(row, priority_list, max_num, initial_y, search_y, y): # ìš°ì„ ìˆœìœ„ì™€ ë°©í–¥ì„ ê³ ë ¤í•˜ì—¬ objectiveë¥¼ ì •í•¨
    target = 0 

    for i in row.index:
        if i in priority_list.keys():
            if priority_list[i][1]=='ìµœëŒ€í™”í•˜ê¸°':
                target+= (max_num-priority_list[i][0]+1)*10*row[i]
        
            else:
                target-= (max_num-priority_list[i][0]+1)*10*row[i]

        else:
            target+=row[i]

    if priority_list[y][1] == "ìµœëŒ€í™”í•˜ê¸°":
        target+= (max_num-priority_list[y][0]+1)*10*initial_y

    elif priority_list[y][1] == "ìµœì†Œí™”í•˜ê¸°":
        target-= (max_num-priority_list[y][0]+1)*10*initial_y
        
    elif priority_list[y][1] == "ëª©í‘œê°’ì— ë§ì¶”ê¸°":
        target-= (max_num-priority_list[y][0]+1)*10*abs(initial_y - search_y[y]["ëª©í‘œê°’"])

    else:
        target-= (max_num-priority_list[y][0]+1)*10*abs(search_y[y]['ë²”ìœ„ ì„¤ì •'].sum()-2*initial_y)

    
    return target


def search(X_train, y_train, model, search_x, search_y):

    start_time = time.time()  # â±ï¸ ìµœì í™” ì‹œì‘ ì‹œê°„ ê¸°ë¡

    y = list(search_y.keys())[0]
    if "ìˆœìœ„" not in search_y[y].keys():
        priority_list = { y : search_y[y]["ëª©í‘œ"]}
    
    else:
        priority_list = { y : [search_y[y]["ìˆœìœ„"], search_y[y]["ëª©í‘œ"]]}

    range_dict = {}

    for i in search_x.keys():
        if search_x[i]["ëª©í‘œ"]=="ìµœì í™”í•˜ì§€ ì•Šê¸°":
            pass
        else:    
            priority_list[i]=[search_x[i]["ìˆœìœ„"], search_x[i]['ëª©í‘œ']]
        
        range_dict[i]=search_x[i]["ë²”ìœ„ ì„¤ì •"]

    
    # single + multi í•©ì¹˜ê¸° ëª©í‘œ
    # multiì˜ ê²½ìš°ì— search_xì—ì„œ ë‹¤ ìµœì í™” ì•Šê¸°ë§Œ ìˆì„ë•ŒëŠ” yë§Œ target -> single
    # ì´ì¤‘ë°˜ë³µë¬¸ search_xë¥¼ ìµœì í™” í•˜ì§€ ì•Šì„ë•Œ, search_yì˜ ëª©í‘œê°€ ë²”ìœ„ì— ë§ì¶”ê¸°ì¸ì§€, ìµœì†Œí™˜ì§€ ìµœëŒ€í™˜ì§€, ëª©í‘œê°’ ë§Œì£¼ê¸´ì§€
    # xëŠ” ìš°ì„ ìˆœìœ„ ë°›ìœ¼ë©´ì„œ targetê°’ë„ ë°›ê³  ìµœì í™” ì¸ì§€ ( + , -) , 

    def optimize_row(index, row):

        # `index`ëŠ” Pandasì˜ ì‹¤ì œ DataFrame ì¸ë±ìŠ¤ì´ë¯€ë¡œ, `y_train`ì—ì„œ ìœ„ì¹˜ë¥¼ ì°¾ì„ ë•Œ `.index.get_loc()` ì‚¬ìš©
        idx_loc = y_train.index.get_loc(index)
        initial_y = y_train.iloc[idx_loc]  # ğŸš€ ì—ëŸ¬ í•´ê²°

        # yë§Œ ìµœì í™” í•˜ë©´ ë˜ëŠ” single objective ìƒí™©
        if len(priority_list)==1:

            target = initial_y

            def objective_function(**kwargs):

                X_simulation = row.copy()  # í˜„ì¬ í–‰ì„ ë³µì‚¬í•˜ì—¬ ì‚¬ìš©

                for key, value in kwargs.items():
                    X_simulation[key] = value  # âœ… ê° Featureì˜ ê°’ì„ ì—…ë°ì´íŠ¸
                
                # ë°ì´í„°ë¥¼ ëª¨ë¸ì— ë§ëŠ” í¬ë§·ìœ¼ë¡œ ë³€í™˜
                input_df = pd.DataFrame([X_simulation])
                prediction = model.predict(input_df)[0]  # 1ê°œì˜ ê°’ ì˜ˆì¸¡
                
                if priority_list[y] == "ìµœëŒ€í™”í•˜ê¸°":
                    return prediction  # ìµœì í™”ëœ ê°€ê²© ë°˜í™˜
                
                elif priority_list[y] == "ìµœì†Œí™”í•˜ê¸°":
                    return - prediction
                    
                elif priority_list[y] == "ëª©í‘œê°’ì— ë§ì¶”ê¸°":
                    return - abs(prediction - search_y[y]["ëª©í‘œê°’"])
                
                else:
                    return - abs(search_y[y]['ë²”ìœ„ ì„¤ì •'].sum()-2* prediction)

                
        else:


            # ğŸ”¹ featureë³„ MinMaxScaler ìƒì„±
            feature_scalers = {col: MinMaxScaler() for col in X_train.columns}
            prediction_scaler = MinMaxScaler()

            # ğŸ”¹ ê° featureë³„ ì •ê·œí™” ë²”ìœ„ í•™ìŠµ
            for col in X_train.columns:
                feature_scalers[col].fit(X_train[[col]])  # ê° ë³€ìˆ˜ì— ëŒ€í•´ fit

            # ğŸ”¹ target(y_train) ì •ê·œí™” í•™ìŠµ
            prediction_scaler.fit(y_train.values.reshape(-1, 1))

            
            max_num = max(map(lambda x: x[0], priority_list.values()))
            target = calculate(row, priority_list, max_num, initial_y, search_y, y)
            
            def objective_function(**kwargs):

                X_simulation = row.copy()  # í˜„ì¬ í–‰ì„ ë³µì‚¬í•˜ì—¬ ì‚¬ìš©
                X_simulation_normalized = X_simulation.copy()  # ë§ˆì°¬ê°€ì§€ë¡œ ë³µì‚¬í•˜ëŠ”ë° ì •ê·œí™”ëœ ê°’ ì €ì¥ìš©

                # ğŸ”¹ kwargs ë‚´ ê° ë³€ìˆ˜ë³„ ì •ê·œí™” ì ìš© 
                for key, value in kwargs.items(): 
                    if key in feature_scalers: # # kwargs ì¡°ì‘ë³€ìˆ˜ë¥¼ ì›ë˜ x_train scalerì™€ ë§¤ì¹­
                        X_simulation_normalized[key] = feature_scalers[key].transform(np.array([[value]]))[0][0]  # ì¡°ì‘ë³€ìˆ˜ ê°œë³„ ì •ê·œí™”
                    X_simulation[key] = value  # ì›ë³¸ ê°’ ìœ ì§€ (model.predictì— ì‚¬ìš©)
                
                # ë°ì´í„°ë¥¼ ëª¨ë¸ì— ë§ëŠ” í¬ë§·ìœ¼ë¡œ ë³€í™˜
                input_df = pd.DataFrame([X_simulation])
                prediction = model.predict(input_df)[0]  # 1ê°œì˜ ê°’ ì˜ˆì¸¡
                prediction_normalized = prediction_scaler.transform(np.array([[prediction]]))[0][0]


                target = calculate(X_simulation_normalized, priority_list, max_num, prediction_normalized, search_y, y)
                
                return target





        # Bayesian Optimization ì‹¤í–‰
        optimizer = BayesianOptimization(
            f=objective_function,
            pbounds={
                i : (range_dict[i][0], range_dict[i][1]) for i in range_dict.keys()
            },
            random_state=42,
            allow_duplicate_points=True
        )

        # ê¸°ì¡´ X_simulationì˜ ê°’ì„ ì´ˆê¸° ê°’ìœ¼ë¡œ ì„¤ì •
        optimizer.register(
            params={i : row[i] for i in search_x.keys()}, 
            target=target  # âœ… ì´ˆê¸° ê°€ê²© ê°’ì„ Bayesian Optimizationì— ë“±ë¡  ## ì´ë ‡ê²Œ í•´ë„ ë˜ë‚˜?
        )

        utility = UtilityFunction(kind="ei", xi=0.1)
        optimizer.maximize(init_points=10, n_iter=30, acquisition_function=utility) #acquisition_function=utility

        # ìµœì ì˜ ê²°ê³¼ ì €ì¥
        best_solution = optimizer.max['params']

        # âœ… ì›ë³¸ ë°ì´í„°(row) ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡œìš´ DataFrame ìƒì„± (ìµœì í™”í•˜ì§€ ì•Šì€ ë³€ìˆ˜ í¬í•¨)
        best_x_df = row.copy()  # ê¸°ì¡´ rowì˜ ëª¨ë“  feature í¬í•¨
        for key, value in best_solution.items():
            best_x_df[key] = value  # âœ… ìµœì í™”ëœ feature ê°’ ì—…ë°ì´íŠ¸

        # âœ… DataFrameìœ¼ë¡œ ë³€í™˜ í›„, feature ìˆœì„œ ë§ì¶”ê¸°
        best_x_df = pd.DataFrame([best_x_df])
        best_x_df = best_x_df.reindex(columns=X_train.columns, fill_value=0)  # ëˆ„ë½ëœ featureëŠ” 0ìœ¼ë¡œ ì±„ì›€

        # âœ… ëª¨ë¸ ì˜ˆì¸¡
        y_pred = model.predict(best_x_df)[0]

        dict1 = {i: best_solution[i] for i in search_x.keys()}
        dict2 = {
            'index': index,
            'target': optimizer.max['target'],  # ê¸°ì¡´ ìµœì í™”ëœ target ê°’
            'y': y_pred  # ğŸš€ ëª¨ë¸ì´ ìµœì  x ê°’ì—ì„œ ì˜ˆì¸¡í•œ y ê°’ ì¶”ê°€
        }

        return {**dict1,**dict2}

    # ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰ (n_jobs=-1: ëª¨ë“  CPU ì½”ì–´ ì‚¬ìš©)
    optimal_solutions = Parallel(n_jobs=-1, backend="loky")(
        delayed(optimize_row)(index, row) for index, row in X_train.iterrows()
    )

    optimal_solutions = [sol for sol in optimal_solutions]

    # âœ… ìµœì  ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥
    optimal_solutions_df = pd.DataFrame(optimal_solutions)

    # â±ï¸ ì¢…ë£Œ ì‹œê°„ ê¸°ë¡ ë° ì¶œë ¥
    end_time = time.time()
    elapsed_time = end_time - start_time


    return elapsed_time, optimal_solutions_df

